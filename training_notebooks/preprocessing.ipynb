{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (user acess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Directory containing the CSV files\n",
    "input_folder = 'C:/Users/eng3/Documents/pos/Tech Challenger 5/dataset/files/treino'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.csv'):  \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_user_acc = combined_df\n",
    "\n",
    "required_columns = ['history', 'timestampHistory', 'numberOfClicksHistory', 'timeOnPageHistory', \n",
    "                    'scrollPercentageHistory', 'pageVisitsCountHistory']\n",
    "df_user_acc = df_user_acc.dropna(subset=required_columns)\n",
    "\n",
    "df_user_acc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (news metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Directory containing the CSV files\n",
    "input_folder = 'C:/Users/eng3/Documents/pos/Tech Challenger 5/dataset/itens/itens/filtered_output'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.csv'):  \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_news_acc = combined_df\n",
    "\n",
    "df_news_acc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess df_news_acc to create a mapping\n",
    "page_to_article_type = df_news_acc.set_index('page')['article-type'].to_dict()\n",
    "\n",
    "# Step 2: Define a faster function using the preprocessed dictionary\n",
    "def process_values(row):\n",
    "    # Remove spaces and split history into IDs\n",
    "    news_ids = row.replace(\" \", \"\").split(',')\n",
    "    \n",
    "    # Map IDs to their article types using the dictionary\n",
    "    ret = [page_to_article_type.get(news, \"Unknown\") for news in news_ids]\n",
    "    \n",
    "    # Join the result as a comma-separated string\n",
    "    retString = \"\"\n",
    "\n",
    "    try:\n",
    "        retString = \",\".join(ret)\n",
    "    except:\n",
    "        retString = \"\"\n",
    "        \n",
    "    return retString\n",
    "\n",
    "\n",
    "# Step 3: Apply the optimized function to the 'history' column\n",
    "df_user_acc['article_types'] = df_user_acc['history'].apply(process_values)\n",
    "\n",
    "# Step 4 (optional): Check the results\n",
    "print(df_user_acc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_acc['history'] = df_user_acc['history'].astype(str).apply(lambda x: x.split(', '))\n",
    "df_user_acc['article_types'] = df_user_acc['article_types'].astype(str).apply(lambda x: x.split(',') if x != 'nan' else [])\n",
    "\n",
    "# Export to parquet\n",
    "df_user_acc.to_parquet('recommendation.parquet', index=False)\n",
    "\n",
    "print(\"DataFrame exported to 'recommendation.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_acc.to_parquet('news_processed.parquet')\n",
    "\n",
    "print(\"DataFrame exported to 'news_processed.parquet'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
