{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (user acess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Directory containing the CSV files\n",
    "input_folder = 'C:/Users/eng3/Documents/pos/Tech Challenger 5/dataset/files/treino'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.csv'):  \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_user_acc = combined_df\n",
    "\n",
    "required_columns = ['history', 'timestampHistory', 'numberOfClicksHistory', 'timeOnPageHistory', \n",
    "                    'scrollPercentageHistory', 'pageVisitsCountHistory']\n",
    "df_user_acc = df_user_acc.dropna(subset=required_columns)\n",
    "\n",
    "df_user_acc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (news metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Directory containing the CSV files\n",
    "input_folder = 'C:/Users/eng3/Documents/pos/Tech Challenger 5/dataset/itens/itens/filtered_output'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.csv'):  \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_news_acc = combined_df\n",
    "\n",
    "df_news_acc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess df_news_acc to create a mapping\n",
    "page_to_article_type = df_news_acc.set_index('page')['article-type'].to_dict()\n",
    "\n",
    "# Step 2: Define a faster function using the preprocessed dictionary\n",
    "def process_values(row):\n",
    "    # Remove spaces and split history into IDs\n",
    "    news_ids = row.replace(\" \", \"\").split(',')\n",
    "    \n",
    "    # Map IDs to their article types using the dictionary\n",
    "    ret = [page_to_article_type.get(news, \"Unknown\") for news in news_ids]\n",
    "    \n",
    "    # Join the result as a comma-separated string\n",
    "    retString = \"\"\n",
    "\n",
    "    try:\n",
    "        retString = \",\".join(ret)\n",
    "    except:\n",
    "        retString = \"\"\n",
    "        \n",
    "    return retString\n",
    "\n",
    "\n",
    "# Step 3: Apply the optimized function to the 'history' column\n",
    "df_user_acc['article_types'] = df_user_acc['history'].apply(process_values)\n",
    "\n",
    "print(df_user_acc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df_user_acc.to_csv('proceded.csv', index=False)\n",
    "\n",
    "print(\"DataFrame exported to 'proceded.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_acc['history'] = df_user_acc['history'].apply(lambda x: x.split(', '))\n",
    "df_user_acc['article_types'] = df_user_acc['article_types'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess multi-value columns\n",
    "\n",
    "\n",
    "\n",
    "# Function to recommend articles\n",
    "def recommend_content_based(user_id, users_data, articles_data):\n",
    "    # Get user data\n",
    "    user_row = users_data[users_data['userId'] == user_id]\n",
    "    if user_row.empty:\n",
    "        return []\n",
    "    \n",
    "    # Extract user preferences\n",
    "    user_history = set(user_row['history'].iloc[0])  # Articles already read\n",
    "    user_article_types = set(user_row['article_types'].iloc[0])  # User's interests\n",
    "    \n",
    "    # Filter articles the user hasn't read\n",
    "    potential_articles = articles_data[~articles_data['page'].isin(user_history)]\n",
    "    \n",
    "    # Recommend articles that match the user's preferred types\n",
    "    recommendations = potential_articles[potential_articles['article-type'].isin(user_article_types)]\n",
    "    \n",
    "    # Sort recommendations by the 'modified' column (most recent first)\n",
    "    recommendations = recommendations.sort_values(by='modified', ascending=False)\n",
    "    \n",
    "    # Return recommended articles\n",
    "    return recommendations[['page', 'url', 'article-type']].to_dict(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test the recommendation system for a user\n",
    "#user_id = \"f98d1132f60d46883ce49583257104d15ce723b3bbda2147c1e31ac76f0bf069\"\n",
    "user_id = \"fake1\"\n",
    "recommendations = recommend_content_based(user_id, df_user_acc, df_news_acc)\n",
    "print(\"Recommended articles:\", recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse multi-value columns\n",
    "data['history'] = data['history'].apply(lambda x: x.split(', '))\n",
    "data['timestampHistory'] = data['timestampHistory'].apply(lambda x: [int(ts) for ts in x.split(', ')])\n",
    "data['article_type'] = data['article_type'].apply(lambda x: x.split())\n",
    "\n",
    "# Function to recommend articles based on content similarity\n",
    "def recommend_articles(user_id, data, article_metadata):\n",
    "    user_row = data[data['userId'] == user_id]\n",
    "    if user_row.empty:\n",
    "        return []\n",
    "    \n",
    "    # Extract user's article types and engagement history\n",
    "    user_article_types = user_row['article_type'].iloc[0]\n",
    "    \n",
    "    # Match articles with similar types\n",
    "    recommendations = []\n",
    "    for article_id, types in article_metadata.items():\n",
    "        if any(t in user_article_types for t in types):  # Check for type overlap\n",
    "            recommendations.append(article_id)\n",
    "    \n",
    "    # Exclude already visited articles\n",
    "    visited = set(user_row['history'].iloc[0])\n",
    "    recommendations = [r for r in recommendations if r not in visited]\n",
    "    \n",
    "    return recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
